{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('imbalanced_env': conda)"
  },
  "interpreter": {
   "hash": "8a2a0f82f110b4117092850e843ebcded4096f088ba2a18a86cc5c678d7800ad"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    recall_score,\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    ")\n",
    "\n",
    "from imblearn.metrics import (\n",
    "    geometric_mean_score,\n",
    "    make_index_balanced_accuracy,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_folder = pathlib.Path(\"../../../Datasets\")\n",
    "dataset_file = \"kdd2004.csv\"\n",
    "dataset_path = datasets_folder/dataset_file\n",
    "\n",
    "if not dataset_path.exists():\n",
    "    raise FileExistsError(f\"The file whose path {dataset_path.resolve()} doesn't exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      0      1     2     3     4       5     6     7     8     9  ...      65  \\\n",
       "0  52.0  32.69  0.30   2.5  20.0  1256.8 -0.89  0.33  11.0 -55.0  ...  1595.1   \n",
       "1  58.0  33.33  0.00  16.5   9.5   608.1  0.50  0.07  20.5 -52.5  ...   762.9   \n",
       "2  77.0  27.27 -0.91   6.0  58.5  1623.6 -1.40  0.02  -6.5 -48.0  ...  1491.8   \n",
       "3  41.0  27.91 -0.35   3.0  46.0  1921.6 -1.36 -0.47 -32.0 -51.5  ...  2047.7   \n",
       "4  50.0  28.00 -1.32  -9.0  12.0   464.8  0.88  0.19   8.0 -51.5  ...   479.5   \n",
       "\n",
       "     66    67   68    69     70    71    72    73  target  \n",
       "0 -1.64  2.83 -2.0 -50.0  445.2 -0.35  0.26  0.76       0  \n",
       "1  0.29  0.82 -3.0 -35.0  140.3  1.16  0.39  0.73       0  \n",
       "2  0.32 -1.29  0.0 -34.0  658.2 -0.76  0.26  0.24       0  \n",
       "3 -0.98  1.53  0.0 -49.0  554.2 -0.83  0.39  0.73       0  \n",
       "4  0.68 -0.59  2.0 -36.0   -6.9  2.02  0.14 -0.23       0  \n",
       "\n",
       "[5 rows x 75 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>65</th>\n      <th>66</th>\n      <th>67</th>\n      <th>68</th>\n      <th>69</th>\n      <th>70</th>\n      <th>71</th>\n      <th>72</th>\n      <th>73</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>52.0</td>\n      <td>32.69</td>\n      <td>0.30</td>\n      <td>2.5</td>\n      <td>20.0</td>\n      <td>1256.8</td>\n      <td>-0.89</td>\n      <td>0.33</td>\n      <td>11.0</td>\n      <td>-55.0</td>\n      <td>...</td>\n      <td>1595.1</td>\n      <td>-1.64</td>\n      <td>2.83</td>\n      <td>-2.0</td>\n      <td>-50.0</td>\n      <td>445.2</td>\n      <td>-0.35</td>\n      <td>0.26</td>\n      <td>0.76</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>58.0</td>\n      <td>33.33</td>\n      <td>0.00</td>\n      <td>16.5</td>\n      <td>9.5</td>\n      <td>608.1</td>\n      <td>0.50</td>\n      <td>0.07</td>\n      <td>20.5</td>\n      <td>-52.5</td>\n      <td>...</td>\n      <td>762.9</td>\n      <td>0.29</td>\n      <td>0.82</td>\n      <td>-3.0</td>\n      <td>-35.0</td>\n      <td>140.3</td>\n      <td>1.16</td>\n      <td>0.39</td>\n      <td>0.73</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>77.0</td>\n      <td>27.27</td>\n      <td>-0.91</td>\n      <td>6.0</td>\n      <td>58.5</td>\n      <td>1623.6</td>\n      <td>-1.40</td>\n      <td>0.02</td>\n      <td>-6.5</td>\n      <td>-48.0</td>\n      <td>...</td>\n      <td>1491.8</td>\n      <td>0.32</td>\n      <td>-1.29</td>\n      <td>0.0</td>\n      <td>-34.0</td>\n      <td>658.2</td>\n      <td>-0.76</td>\n      <td>0.26</td>\n      <td>0.24</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>41.0</td>\n      <td>27.91</td>\n      <td>-0.35</td>\n      <td>3.0</td>\n      <td>46.0</td>\n      <td>1921.6</td>\n      <td>-1.36</td>\n      <td>-0.47</td>\n      <td>-32.0</td>\n      <td>-51.5</td>\n      <td>...</td>\n      <td>2047.7</td>\n      <td>-0.98</td>\n      <td>1.53</td>\n      <td>0.0</td>\n      <td>-49.0</td>\n      <td>554.2</td>\n      <td>-0.83</td>\n      <td>0.39</td>\n      <td>0.73</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>50.0</td>\n      <td>28.00</td>\n      <td>-1.32</td>\n      <td>-9.0</td>\n      <td>12.0</td>\n      <td>464.8</td>\n      <td>0.88</td>\n      <td>0.19</td>\n      <td>8.0</td>\n      <td>-51.5</td>\n      <td>...</td>\n      <td>479.5</td>\n      <td>0.68</td>\n      <td>-0.59</td>\n      <td>2.0</td>\n      <td>-36.0</td>\n      <td>-6.9</td>\n      <td>2.02</td>\n      <td>0.14</td>\n      <td>-0.23</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 75 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "df[\"target\"] = df[\"target\"].map({-1:0, 1:1})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    0.991108\n",
       "1    0.008892\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df[\"target\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((102025, 74), (43726, 74))"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(labels=[\"target\"], axis=1),\n",
    "    df[\"target\"],\n",
    "    test_size=0.3,\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\safou\\anaconda3\\envs\\imbalanced_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# Baseline model\n",
    "y_train_baseline = pd.Series(np.zeros_like(y_train))\n",
    "y_test_baseline = pd.Series(np.zeros_like(y_test))\n",
    "\n",
    "# Random forest\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=2)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Logistic regression\n",
    "logit = LogisticRegression(max_iter=1000)\n",
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Recall - Baseline model: 0.0\nRecall - Random forest model: 0.5800524934383202\nRecall - Logistic regression model: 0.7007874015748031\n"
     ]
    }
   ],
   "source": [
    "# TPR = Recall = tp / (tp + fn)\n",
    "print(f\"Recall - Baseline model: {recall_score(y_test, y_test_baseline)}\")\n",
    "print(f\"Recall - Random forest model: {recall_score(y_test, rf.predict(X_test))}\")\n",
    "print(f\"Recall - Logistic regression model: {recall_score(y_test, logit.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TNR - Baseline model: 1.0\nTNR - Random forest model: 0.9999307878648056\nTNR - Logistic regression model: 0.9995385857653709\n"
     ]
    }
   ],
   "source": [
    "# TNR = tn / (tn + fp)\n",
    "# We can use recall_score function but the positive label should be the negative class\n",
    "print(f\"TNR - Baseline model: {recall_score(y_test, y_test_baseline, pos_label=0)}\")\n",
    "print(f\"TNR - Random forest model: {recall_score(y_test, rf.predict(X_test), pos_label=0)}\")\n",
    "print(f\"TNR - Logistic regression model: {recall_score(y_test, logit.predict(X_test), pos_label=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "G-mean - Baseline model: 0.0\nG-mean - Random forest model: 0.7615854165927316\nG-mean - Logistic regression model: 0.836937302485836\n"
     ]
    }
   ],
   "source": [
    "# Geometric mean = sqrt(recall * TNR)\n",
    "print(f\"G-mean - Baseline model: {geometric_mean_score(y_test, y_test_baseline)}\")\n",
    "print(f\"G-mean - Random forest model: {geometric_mean_score(y_test, rf.predict(X_test))}\")\n",
    "print(f\"G-mean - Logistic regression model: {geometric_mean_score(y_test, logit.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dominance = TPR - TNR\n",
    "def dominance(y_true, y_pred):\n",
    "    tpr = recall_score(y_true, y_pred, pos_label=1)\n",
    "    tnr = recall_score(y_true, y_pred, pos_label=0)\n",
    "    return tpr - tnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dominance - Baseline model: -1.0\n",
      "Dominance - Random forest model: -0.4198782944264854\n",
      "Dominance - Logistic regression model: -0.2987511841905678\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dominance - Baseline model: {dominance(y_test, y_test_baseline)}\")\n",
    "print(f\"Dominance - Random forest model: {dominance(y_test, rf.predict(X_test))}\")\n",
    "print(f\"Dominance - Logistic regression model: {dominance(y_test, logit.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Balanced geometric mean - Baseline model: 0.0\nBalanced geometric mean - Random forest model: 0.5800123467667245\nBalanced geometric mean - Logistic regression model: 0.7004640482922677\n"
     ]
    }
   ],
   "source": [
    "# Index balanced accuracy applied on geometric mean\n",
    "balanced_gmean = make_index_balanced_accuracy(alpha=0.5, squared=True)(geometric_mean_score)\n",
    "\n",
    "print(f\"Balanced geometric mean - Baseline model: {balanced_gmean(y_test, y_test_baseline)}\")\n",
    "print(f\"Balanced geometric mean - Random forest model: {balanced_gmean(y_test, rf.predict(X_test))}\")\n",
    "print(f\"Balanced geometric mean - Logistic regression model: {balanced_gmean(y_test, logit.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "---------- Accuracy -----------------\n",
      "Accuracy - Baseline model: 0.991286648675845\n",
      "Accuracy - Random forest model: 0.9962722407720807\n",
      "Accuracy - Logistic regression model: 0.9969354617390112\n",
      "---------- Balanced Accuracy -----------------\n",
      "Accuracy - Baseline model: 0.4913246099214941\n",
      "Accuracy - Random forest model: 0.7841815183523922\n",
      "Accuracy - Logistic regression model: 0.8454188543668073\n",
      "---------- Built-in Balanced Accuracy -----------------\n",
      "Accuracy - Baseline model: 0.5\n",
      "Accuracy - Random forest model: 0.7899916406515629\n",
      "Accuracy - Logistic regression model: 0.850162993670087\n"
     ]
    }
   ],
   "source": [
    "# Comparison of the accuracy and the balanced accuracy using IBA\n",
    "print(\"---------- Accuracy -----------------\")\n",
    "print(f\"Accuracy - Baseline model: {accuracy_score(y_test, y_test_baseline)}\")\n",
    "print(f\"Accuracy - Random forest model: {accuracy_score(y_test, rf.predict(X_test))}\")\n",
    "print(f\"Accuracy - Logistic regression model: {accuracy_score(y_test, logit.predict(X_test))}\")\n",
    "\n",
    "balanced_accuracy = make_index_balanced_accuracy(alpha=0.5, squared=True)(accuracy_score)\n",
    "\n",
    "print(\"---------- Balanced Accuracy using IBA -----------------\")\n",
    "print(f\"Accuracy - Baseline model: {balanced_accuracy(y_test, y_test_baseline)}\")\n",
    "print(f\"Accuracy - Random forest model: {balanced_accuracy(y_test, rf.predict(X_test))}\")\n",
    "print(f\"Accuracy - Logistic regression model: {balanced_accuracy(y_test, logit.predict(X_test))}\")\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Balanced accuracy\n",
    "\n",
    "Balanced accuracy is just the average of the model accuracy for each class.\n",
    "\n",
    "![Balanced accuracy](../../../_assets/Balanced_accuracy.PNG)\n",
    "\n",
    "Note: The image above is a screenshot from one of Andreas Mueller lectures: Applied ML 2020 - 09 - Model Evaluation and Metrics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------- Built-in Balanced Accuracy -----------------\")\n",
    "print(f\"Accuracy - Baseline model: {balanced_accuracy_score(y_test, y_test_baseline)}\")\n",
    "print(f\"Accuracy - Random forest model: {balanced_accuracy_score(y_test, rf.predict(X_test))}\")\n",
    "print(f\"Accuracy - Logistic regression model: {balanced_accuracy_score(y_test, logit.predict(X_test))}\")"
   ]
  }
 ]
}